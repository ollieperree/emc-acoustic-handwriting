{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrogram-based resnet digit classifier using fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "from librosa import display\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to data directory and recordings directory\n",
    "DATA = Path(\"../../data/words/\")\n",
    "RECORDINGS = DATA/\"audio-recordings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav(filename):\n",
    "    return librosa.core.load(filename, sr=None, mono=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(DATA/\"labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_spectrogram(wav_path, save_path):\n",
    "    plt.clf()\n",
    "    data, sr = load_wav(wav_path)\n",
    "    trimmed, idx = librosa.effects.trim(data, top_db=30)\n",
    "    spec = librosa.feature.melspectrogram(trimmed, sr, n_fft=2048, hop_length=256)\n",
    "    librosa.display.specshow(librosa.core.power_to_db(spec))\n",
    "    cur_axes = plt.gca().set_axis_off()\n",
    "    plt.savefig(save_path, bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(fname):\n",
    "    save_spectrogram(DATA/\"processed\"/fname, DATA/\"spectrograms\"/fname.replace(\".wav\", \".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm ../../data/words/spectrograms/*.png\n",
    "\n",
    "if not (DATA/\"spectrograms\").exists():\n",
    "    (DATA/\"spectrograms\").mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b8a7f892bd74b3b99e7bb6fd369f71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3825.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pool = mp.Pool(4)  # Use 4 processes\n",
    "\n",
    "for fname in tqdm(labels_df[\"filename\"]):\n",
    "    pool.apply(process_file, args=(fname,))\n",
    "    \n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai import metrics\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe which has filenames ending in .png instead of .wav\n",
    "spec_labels_df = labels_df.copy()\n",
    "spec_labels_df[\"filename\"] = spec_labels_df[\"filename\"].apply(lambda x: x.replace(\".wav\", \".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(valid_split_no, bs=32):\n",
    "    df = spec_labels_df[spec_labels_df[f\"valid{valid_split_no}\"] != -1]\n",
    "    return (ImageList.from_df(df, DATA/\"spectrograms\")\n",
    "            .split_from_df(col=f\"valid{valid_split_no}\")\n",
    "            .label_from_df(cols=\"label\")\n",
    "            .databunch(bs=bs)\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_SPLITS = [1, 2, 3]\n",
    "MODELS = [\n",
    "    #models.resnet18,\n",
    "    #models.resnet34,\n",
    "    models.resnet50,\n",
    "    #models.resnet101,\n",
    "    models.densenet121,\n",
    "    models.densenet161\n",
    "]\n",
    "PRETRAINED = [True, False]\n",
    "USE_MIXUP = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "SPLIT 1\n",
      "************************************\n",
      "model=resnet50, pretrained=True, mixup=True\n",
      "epoch     train_loss  valid_loss  accuracy  precision  recall    time    \n",
      "0         5.578439    4.533839    0.041667  nan        0.041667  00:21     \n",
      "1         4.934674    4.355747    0.063889  nan        0.063889  00:20     \n",
      "2         4.508043    4.250220    0.056944  nan        0.056944  00:20     \n",
      "3         4.159351    4.277453    0.065278  nan        0.065278  00:20     \n",
      "4         3.976144    4.297225    0.065278  nan        0.065278  00:20     \n",
      "5         3.803868    4.341218    0.068056  nan        0.068056  00:20     \n",
      "6         3.760157    4.212197    0.066667  nan        0.066667  00:20     \n",
      "7         3.691179    4.235294    0.073611  nan        0.073611  00:20     \n",
      "8         3.588504    4.182394    0.088889  nan        0.088889  00:20     \n",
      "9         3.565894    4.393504    0.102778  nan        0.102778  00:20     \n",
      "10        3.579708    4.246653    0.104167  nan        0.104167  00:20     \n",
      "11        3.539229    4.069654    0.123611  nan        0.123611  00:20     \n",
      "12        3.494209    3.970080    0.118056  nan        0.118056  00:20     \n",
      "13        3.351935    3.691645    0.133333  nan        0.133333  00:20     \n",
      "14        3.259842    3.468730    0.187500  nan        0.187500  00:20     \n",
      "15        3.147861    3.717619    0.166667  nan        0.166667  00:20     \n",
      "16        3.118473    3.481404    0.176389  nan        0.176389  00:20     \n",
      "17        3.001594    3.251665    0.212500  nan        0.212500  00:20     \n",
      "18        2.941547    3.416379    0.195833  nan        0.195833  00:20     \n",
      "19        2.906137    3.306312    0.200000  nan        0.200000  00:20     \n",
      "20        2.792853    3.097806    0.230556  nan        0.230556  00:20     \n",
      "21        2.760335    3.112085    0.233333  nan        0.233333  00:20     \n",
      "22        2.708142    3.142551    0.229167  nan        0.229167  00:20     \n",
      "23        2.639807    3.039157    0.250000  nan        0.250000  00:20     \n",
      "24        2.595107    2.904114    0.293056  nan        0.293056  00:20     \n",
      "25        2.549199    3.110147    0.259722  nan        0.259722  00:20     \n",
      "26        2.509660    2.786766    0.315278  nan        0.315278  00:20     \n",
      "27        2.443237    2.834927    0.284722  nan        0.284722  00:20     \n",
      "28        2.431470    3.153735    0.256944  nan        0.256944  00:20     \n",
      "29        2.392058    2.667402    0.316667  nan        0.316667  00:20     \n",
      "30        2.339195    3.102676    0.281944  nan        0.281944  00:20     \n",
      "31        2.271508    2.882290    0.305556  nan        0.305556  00:20     \n",
      "32        2.225568    2.860432    0.297222  nan        0.297222  00:20     \n",
      "â–ˆ\r"
     ]
    }
   ],
   "source": [
    "for valid_split in VALID_SPLITS:\n",
    "    print(f\"************************************\\nSPLIT {valid_split}\\n************************************\")\n",
    "    for model in MODELS:\n",
    "        for pretrained in PRETRAINED:\n",
    "            for use_mixup in USE_MIXUP:\n",
    "                # Free up GPU memory\n",
    "                print(f\"model={model.__name__}, pretrained={pretrained}, mixup={use_mixup}\")\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                learn = cnn_learner(get_data(valid_split, bs=32),\n",
    "                                    model,\n",
    "                                    pretrained=pretrained,\n",
    "                                    metrics=[accuracy, metrics.Precision(average=\"macro\"), metrics.Recall(average=\"macro\")],\n",
    "                                    # Using macro average precision and recall\n",
    "                                    callback_fns=[ShowGraph,\n",
    "                                                  partial(callbacks.CSVLogger, filename=f\"Split{valid_split}_{model.__name__},pretrained={int(pretrained)},mixup={int(use_mixup)}\")\n",
    "                                                 ]).to_fp16()\n",
    "                if use_mixup:\n",
    "                    learn = learn.mixup()\n",
    "\n",
    "                learn.fit_one_cycle(100, max_lr=1e-2)\n",
    "                learn.export(f\"Split{valid_split}_{model.__name__},pretrained={int(pretrained)},mixup={int(use_mixup)}\")\n",
    "                del learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
